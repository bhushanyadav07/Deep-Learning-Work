{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNlbdx7gpwfxpZKv45vXdLa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhushanyadav07/Deep-Learning-Work/blob/master/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBqTZmWJKfHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en\") #load the english language model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zvATmYQuyb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"Tea is healthy and calming, don't you think?\") #with loaded model we can process the text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiZcxsFHzVqB",
        "colab_type": "text"
      },
      "source": [
        "**Tokenizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1yjFEq0u_ko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ff4dcc7f-3f6f-48ad-982a-88c428c65a67"
      },
      "source": [
        "#tokenizing\n",
        "for token in doc:\n",
        "  print(token)  #here we can what spacy does - spacy split contractions like \"don't\" into two parts"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tea\n",
            "is\n",
            "healthy\n",
            "and\n",
            "calming\n",
            ",\n",
            "do\n",
            "n't\n",
            "you\n",
            "think\n",
            "?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0GyLx3ZzbVV",
        "colab_type": "text"
      },
      "source": [
        "**Text** **pre-processing**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx9hgOX7zgD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1d4ce209-d9a9-405d-fa86-ccf4d59ec1a2"
      },
      "source": [
        "print(f\"Token \\t\\t Lemma\\t\\t Stopwords\".format('Token', 'Lemma', 'Stopwords'))\n",
        "print('-'*45)\n",
        "for token in doc:\n",
        "  print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\") #lemma is used convert the lemmitizing words like calming into clam"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token \t\t Lemma\t\t Stopwords\n",
            "---------------------------------------------\n",
            "Tea\t\ttea\t\tFalse\n",
            "is\t\tbe\t\tTrue\n",
            "healthy\t\thealthy\t\tFalse\n",
            "and\t\tand\t\tTrue\n",
            "calming\t\tcalm\t\tFalse\n",
            ",\t\t,\t\tFalse\n",
            "do\t\tdo\t\tTrue\n",
            "n't\t\tnot\t\tTrue\n",
            "you\t\t-PRON-\t\tTrue\n",
            "think\t\tthink\t\tFalse\n",
            "?\t\t?\t\tFalse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMArzGkR85Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "matcher = PhraseMatcher(nlp.vocab, attr = 'LOWER') #setting the atte = lower which means the phrases matches on lowercase text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_I2XKtispSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terms = ['Galaxy Note', 'iPhone 11', 'iPhone XS', 'Google Pixel']\n",
        "patterns = [nlp(text) for text in terms]\n",
        "matcher.add(\"TerminologyList\", None, *patterns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dOpjUYS21uT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33d74613-ca4e-43b7-d8e8-57edb92c1c7b"
      },
      "source": [
        "# Borrowed from https://daringfireball.net/linked/2019/09/21/patel-11-pro\n",
        "text_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\n",
        "               \"photography tests pitting the iPhone 11 Pro against the \"\n",
        "               \"Galaxy Note 10 Plus and last yearâ€™s iPhone XS and Google Pixel 3.\") \n",
        "matches = matcher(text_doc)\n",
        "print(matches)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(3766102292120407359, 17, 19), (3766102292120407359, 22, 24), (3766102292120407359, 30, 32), (3766102292120407359, 33, 35)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NRItvlieP5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d1951da-bcb3-4586-e516-ad890a60aa08"
      },
      "source": [
        "match_id, start, end = matches[0]\n",
        "print(nlp.vocab.strings[match_id], text_doc[start:end])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TerminologyList iPhone 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mQf2UKafQAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9aab0f2f-76a2-4026-bd6d-d96467acb4a4"
      },
      "source": [
        "match_id, start, end = matches[0]\n",
        "print(nlp.vocab.strings[match_id], text_doc[start:end])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TerminologyList iPhone 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vRyclBuaqI5",
        "colab_type": "text"
      },
      "source": [
        "as we can see there are tuple with matching id's and there starting and ending position of the phrase"
      ]
    }
  ]
}